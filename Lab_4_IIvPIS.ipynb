{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d83fb6-8271-45c2-ab5a-cec279c58806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold  # Модули для разделения данных и кросс-валидации\n",
    "from sklearn.neighbors import KNeighborsClassifier  # Классификатор K-ближайших соседей\n",
    "from sklearn.metrics import accuracy_score  # Модуль для оценки точности модели\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9721d0e-ba56-4d01-b005-2645476dc40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "features = ['Sex', 'Pclass', 'SibSp', 'Parch']\n",
    "y = train_data['Survived']\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2337a3db-fa92-4c86-897c-875d1dd3c45e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;66;03m#делаем предсказание\u001b[39;00m\n\u001b[0;32m      5\u001b[0m output \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m'\u001b[39m:test_data\u001b[38;5;241m.\u001b[39mPassengerId, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m:prediction})\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:222\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:119\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    122\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y) #обучаем модель\n",
    "prediction = model.predict(X_test) #делаем предсказание\n",
    "output = pd.DataFrame({'PassengerId':test_data.PassengerId, 'Survived':prediction})\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(X_test, output)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60d9c26d-d77e-4911-b6ed-24c2310cc110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7932960893854749\n"
     ]
    }
   ],
   "source": [
    "y = train_data['Survived']\n",
    "X = pd.get_dummies(train_data[features])\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Обучение и оценка модели K-ближайших соседей\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)  # Обучение модели\n",
    "y_pred = knn.predict(X_test)  # Прогнозирование на тестовой выбор-ке\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")  # Вывод точно-сти модели\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "107d707d-9672-40a6-8226-399ca8f2305a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     k  test_size  accuracy\n",
      "0    1        0.1  0.811111\n",
      "1    1        0.2  0.798883\n",
      "2    1        0.3  0.750000\n",
      "3    1        0.4  0.697479\n",
      "4    3        0.1  0.811111\n",
      "5    3        0.2  0.793296\n",
      "6    3        0.3  0.761194\n",
      "7    3        0.4  0.756303\n",
      "8    5        0.1  0.777778\n",
      "9    5        0.2  0.782123\n",
      "10   5        0.3  0.757463\n",
      "11   5        0.4  0.770308\n",
      "12   7        0.1  0.811111\n",
      "13   7        0.2  0.776536\n",
      "14   7        0.3  0.753731\n",
      "15   7        0.4  0.781513\n",
      "16   9        0.1  0.800000\n",
      "17   9        0.2  0.776536\n",
      "18   9        0.3  0.757463\n",
      "19   9        0.4  0.787115\n",
      "20  11        0.1  0.811111\n",
      "21  11        0.2  0.776536\n",
      "22  11        0.3  0.753731\n",
      "23  11        0.4  0.775910\n",
      "24  13        0.1  0.788889\n",
      "25  13        0.2  0.782123\n",
      "26  13        0.3  0.794776\n",
      "27  13        0.4  0.775910\n",
      "28  15        0.1  0.777778\n",
      "29  15        0.2  0.782123\n",
      "30  15        0.3  0.794776\n",
      "31  15        0.4  0.770308\n"
     ]
    }
   ],
   "source": [
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "test_sizes = [0.1, 0.2, 0.3, 0.4]\n",
    "results_hold_out = []\n",
    "for k in k_values:\n",
    "    for test_size in test_sizes:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results_hold_out.append((k, test_size, accuracy))\n",
    "# Создание DataFrame с результатами hold-out валидации\n",
    "df_hold_out = pd.DataFrame(results_hold_out, columns=['k', 'test_size', 'accuracy'])\n",
    "print(df_hold_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa3e9649-4b79-43c3-9b9a-fca9019e952c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     k  fold  mean_accuracy\n",
      "0    1     3       0.735129\n",
      "1    1     5       0.709347\n",
      "2    1     7       0.711509\n",
      "3    1    10       0.717129\n",
      "4    3     3       0.762065\n",
      "5    3     5       0.738522\n",
      "6    3     7       0.731774\n",
      "7    3    10       0.741798\n",
      "8    5     3       0.794613\n",
      "9    5     5       0.787885\n",
      "10   5     7       0.790135\n",
      "11   5    10       0.781136\n",
      "12   7     3       0.785634\n",
      "13   7     5       0.789015\n",
      "14   7     7       0.792358\n",
      "15   7    10       0.794607\n",
      "16   9     3       0.786756\n",
      "17   9     5       0.790139\n",
      "18   9     7       0.792376\n",
      "19   9    10       0.790125\n",
      "20  11     3       0.786756\n",
      "21  11     5       0.785644\n",
      "22  11     7       0.789010\n",
      "23  11    10       0.785618\n",
      "24  13     3       0.786756\n",
      "25  13     5       0.791250\n",
      "26  13     7       0.793500\n",
      "27  13    10       0.792360\n",
      "28  15     3       0.786756\n",
      "29  15     5       0.785644\n",
      "30  15     7       0.793474\n",
      "31  15    10       0.788989\n"
     ]
    }
   ],
   "source": [
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "folds = [3, 5, 7, 10]\n",
    "results_cv = []\n",
    "\n",
    "for k in k_values:\n",
    "    for fold in folds:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        cv = KFold(n_splits=fold, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(knn, X, y, cv=cv)\n",
    "        results_cv.append((k, fold, np.mean(cv_scores)))\n",
    "# Создание DataFrame с результатами кросс-валидации\n",
    "df_cv = pd.DataFrame(results_cv, columns=['k', 'fold', 'mean_accuracy'])\n",
    "print(df_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34b936f8-0156-453e-bfac-1ecd86a6c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальное значение K: 5.0\n",
      "Финальная точность модели: 0.7703081232492998\n"
     ]
    }
   ],
   "source": [
    "optimal_k = df_cv.loc[df_cv['mean_accuracy'].idxmax()]['k']\n",
    "print(f\"Оптимальное значение K: {optimal_k}\")\n",
    "# Финальная модель с оптимальным K\n",
    "final_knn = KNeighborsClassifier(n_neighbors=int(optimal_k))\n",
    "final_knn.fit(X_train, y_train)\n",
    "y_final_pred = final_knn.predict(X_test)\n",
    "print(f\"Финальная точность модели: {accuracy_score(y_test, y_final_pred)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
